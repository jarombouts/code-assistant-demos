{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Tutorial: ETL-like Operations with Meteo Data using Python\n",
    "\n",
    "# In this tutorial, we will perform the following steps:\n",
    "# 1. Scrape the past 12 months of data in 30-day windows using the '\n",
    "#    api_scraper(start, end)' function.\n",
    "# 2. Convert the results into Pandas DataFrames.\n",
    "# 3. Create an SQLite database and idempotently insert the data into it.\n",
    "# 4. Perform basic querying on the data.\n",
    "#\n",
    "# There are some ugly bugs in the scraper and insertion logic!\n",
    "# Can you AI assistant fix them? And... can your AI assistant help you write\n",
    "# some basic SQL queries to answer questions about the data?\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Import necessary libraries and get the API scraper function\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Step 1: import api scraper.\n",
    "# You can open the python and have Codeium explain you what is happening!\n",
    "# For example, try deleting the docstrings from the conversion functions, and have\n",
    "# Codeium tell you what the (now undocumented) code does!\n",
    "\n",
    "from knmi import api_scraper\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Define a function to scrape past year data in 30-day windows\n",
    "\n",
    "\n",
    "def scrape_past_year_data(api_scraper_func):\n",
    "    # Get today's date\n",
    "    today = datetime.date.today()\n",
    "\n",
    "    # Set the number of days in each window\n",
    "    window_size = 30\n",
    "\n",
    "    # Initialize lists to store the data\n",
    "    data_frames = []\n",
    "    start_date = today - datetime.timedelta(days=365)\n",
    "    end_date = start_date + datetime.timedelta(days=window_size - 1)\n",
    "\n",
    "    while end_date < today:\n",
    "        # Scrape data for the current window\n",
    "        meteo_data = api_scraper_func(start_date, end_date)\n",
    "\n",
    "        # Convert the list of dictionaries to a DataFrame\n",
    "        df = pd.DataFrame(meteo_data)\n",
    "\n",
    "        # Append the DataFrame to the list\n",
    "        data_frames.append(df)\n",
    "\n",
    "        # Move the window forward for the next iteration\n",
    "        start_date = end_date + datetime.timedelta(days=1)\n",
    "        end_date = start_date + datetime.timedelta(days=window_size + 1)\n",
    "\n",
    "    return data_frames\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Create SQLite database and insert data\n",
    "\n",
    "\n",
    "def create_database_and_insert_data(data_frames, db_file):\n",
    "    # Establish a connection to the database\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Iterate through each DataFrame and insert its data into the database\n",
    "    for i, df in enumerate(data_frames):\n",
    "        # Use the DataFrame's 'to_sql' method to insert data into the database\n",
    "        # If the table already exists, 'if_exists' will ensure records are inserted if they don't already exist.\n",
    "        # Here, 'YYYYMMDD' is assumed to be a unique key for each record.\n",
    "        df.to_sql(name=f\"meteo_data\", con=conn, if_exists=\"append\", index=False)\n",
    "        print(f\"Inserted {len(df)} records into table {i + 1} of {len(data_frames)}\")\n",
    "\n",
    "    # Commit the changes and close the database connection\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 4: Perform basic querying on the data\n",
    "\n",
    "\n",
    "def perform_basic_querying(db_file):\n",
    "    # Establish a connection to the database\n",
    "    conn = sqlite3.connect(db_file)\n",
    "\n",
    "    # Query 1: Get the number of records in the table\n",
    "    query1 = \"SELECT COUNT(*) as num_records FROM meteo_data;\"\n",
    "\n",
    "    # Execute the query and fetch the results into a DataFrame\n",
    "    result_df = pd.read_sql_query(query1, conn)\n",
    "\n",
    "    # Print the query result\n",
    "    print(\"Number of records in the table:\")\n",
    "    print(result_df)\n",
    "\n",
    "    # Query 2: Get the average temperature for each month\n",
    "    # works by getting the 5th and 6th character of the YYYMMDD string\n",
    "    query2 = \"\"\"\n",
    "        SELECT AVG(TEMP_GEM) as avg_temperature, SUBSTR(YYYYMMDD, 5, 2) as month\n",
    "        FROM meteo_data\n",
    "        GROUP BY month;\n",
    "        \"\"\"\n",
    "\n",
    "    # Execute the query and fetch the results into a DataFrame\n",
    "    result_df = pd.read_sql_query(query2, conn)\n",
    "\n",
    "    # Print the query results\n",
    "    print(\"\\nAverage temperature for each month:\")\n",
    "    print(result_df)\n",
    "\n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's run the code!\n",
    "# Do you think this nicely fetches EACH day in the year?\n",
    "data_frames = scrape_past_year_data(api_scraper)\n",
    "\n",
    "db_file = \"meteo_data.db\"\n",
    "\n",
    "# Is this insertion code really idempotent? What happens when you run the code twice?\n",
    "create_database_and_insert_data(data_frames, db_file)\n",
    "perform_basic_querying(db_file)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
